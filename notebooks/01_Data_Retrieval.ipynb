{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Extrovert-Introvert Classification - Data Retrieval\n",
        "\n",
        "This notebook handles the data retrieval and initial loading for the extrovert-introvert personality classification project.\n",
        "\n",
        "## Overview\n",
        "- Load raw personality dataset\n",
        "- Initial data inspection and validation\n",
        "- Data quality assessment\n",
        "- Feature identification and analysis\n",
        "- Export processed datasets for further analysis\n",
        "\n",
        "## Dataset Sources\n",
        "1. **Main Dataset**: `data/raw/personality_dataset.csv` - Primary personality classification dataset with behavioral features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Data Loading and Initial Inspection\n",
        "\n",
        "Let's start by loading the personality dataset and understanding its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: c:\\Users\\andre\\Documents\\GithubRepo\\Data Science\\extrovert-introvert-classification\\notebooks\n",
            "\n",
            "============================================================\n",
            "CHECKING DATA DIRECTORIES AND FILES\n",
            "============================================================\n",
            "\n",
            "Data/raw directory found at: ../data/raw/\n",
            "  ../data/raw/personality_datasert.csv (0.11 MB)\n",
            "  ../data/raw/personality_dataset.csv (0.10 MB)\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Function to safely load CSV with different encodings\n",
        "def load_csv_safe(filepath, encodings=['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']):\n",
        "    \"\"\"\n",
        "    Safely load CSV file trying different encodings\n",
        "    \"\"\"\n",
        "    # Try both relative to current dir and relative to parent dir (in case running from notebooks/)\n",
        "    possible_paths = [filepath, os.path.join('..', filepath)]\n",
        "    \n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            for encoding in encodings:\n",
        "                try:\n",
        "                    df = pd.read_csv(path, encoding=encoding)\n",
        "                    print(f\"Successfully loaded {path} with encoding: {encoding}\")\n",
        "                    print(f\"  Shape: {df.shape}, Memory: {df.memory_usage(deep=True).sum()/1024/1024:.2f} MB\")\n",
        "                    return df\n",
        "                except UnicodeDecodeError:\n",
        "                    print(f\"  Failed with {encoding} encoding\")\n",
        "                    continue\n",
        "                except Exception as e:\n",
        "                    print(f\"  Error with {encoding}: {e}\")\n",
        "                    continue\n",
        "    \n",
        "    print(f\"Failed to load {filepath} - file not found in any location\")\n",
        "    return None\n",
        "\n",
        "# Check current working directory and available data files\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CHECKING DATA DIRECTORIES AND FILES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define possible paths (current dir and parent dir)\n",
        "data_dirs = [\"data/raw/\", \"../data/raw/\"]\n",
        "\n",
        "found_data_dir = None\n",
        "\n",
        "# Check for data/raw directory\n",
        "for data_dir in data_dirs:\n",
        "    if os.path.exists(data_dir):\n",
        "        found_data_dir = data_dir\n",
        "        print(f\"\\nData/raw directory found at: {data_dir}\")\n",
        "        for root, dirs, files in os.walk(data_dir):\n",
        "            for file in files:\n",
        "                filepath = os.path.join(root, file)\n",
        "                if file.endswith('.csv'):\n",
        "                    file_size = os.path.getsize(filepath) / 1024 / 1024  # MB\n",
        "                    print(f\"  {filepath} ({file_size:.2f} MB)\")\n",
        "        break\n",
        "\n",
        "if not found_data_dir:\n",
        "    print(\"\\nData/raw directory: NOT FOUND\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Loading Main Personality Dataset\n",
        "\n",
        "Loading the primary personality classification dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "LOADING MAIN PERSONALITY DATASET\n",
            "============================================================\n",
            "Successfully loaded ..\\data/raw/personality_dataset.csv with encoding: utf-8\n",
            "  Shape: (2900, 8), Memory: 0.55 MB\n",
            "\n",
            "MAIN DATASET SUMMARY:\n",
            "   Shape: (2900, 8)\n",
            "   Columns: ['Time_spent_Alone', 'Stage_fear', 'Social_event_attendance', 'Going_outside', 'Drained_after_socializing', 'Friends_circle_size', 'Post_frequency', 'Personality']\n",
            "   Memory: 0.55 MB\n",
            "\n",
            "FIRST 3 ROWS:\n",
            "   Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
            "0               4.0         No                      4.0            6.0   \n",
            "1               9.0        Yes                      0.0            0.0   \n",
            "2               9.0        Yes                      1.0            2.0   \n",
            "\n",
            "  Drained_after_socializing  Friends_circle_size  Post_frequency Personality  \n",
            "0                        No                 13.0             5.0   Extrovert  \n",
            "1                       Yes                  0.0             3.0   Introvert  \n",
            "2                       Yes                  5.0             2.0   Introvert  \n",
            "\n",
            "DATASET INFO:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2900 entries, 0 to 2899\n",
            "Data columns (total 8 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Time_spent_Alone           2837 non-null   float64\n",
            " 1   Stage_fear                 2827 non-null   object \n",
            " 2   Social_event_attendance    2838 non-null   float64\n",
            " 3   Going_outside              2834 non-null   float64\n",
            " 4   Drained_after_socializing  2848 non-null   object \n",
            " 5   Friends_circle_size        2823 non-null   float64\n",
            " 6   Post_frequency             2835 non-null   float64\n",
            " 7   Personality                2900 non-null   object \n",
            "dtypes: float64(5), object(3)\n",
            "memory usage: 181.4+ KB\n",
            "None\n",
            "\n",
            "IDENTIFIED COLUMNS:\n",
            "   Behavioral features: ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Drained_after_socializing', 'Friends_circle_size', 'Post_frequency']\n",
            "   Psychological indicators: ['Stage_fear', 'Drained_after_socializing']\n",
            "   Target variables: ['Personality']\n"
          ]
        }
      ],
      "source": [
        "# Load main personality dataset\n",
        "print(\"=\"*60)\n",
        "print(\"LOADING MAIN PERSONALITY DATASET\")\n",
        "print(\"=\"*60)\n",
        "main_df = load_csv_safe(\"data/raw/personality_dataset.csv\")\n",
        "\n",
        "if main_df is not None:\n",
        "    print(f\"\\nMAIN DATASET SUMMARY:\")\n",
        "    print(f\"   Shape: {main_df.shape}\")\n",
        "    print(f\"   Columns: {list(main_df.columns)}\")\n",
        "    print(f\"   Memory: {main_df.memory_usage(deep=True).sum()/1024/1024:.2f} MB\")\n",
        "    \n",
        "    print(f\"\\nFIRST 3 ROWS:\")\n",
        "    print(main_df.head(3))\n",
        "    \n",
        "    print(f\"\\nDATASET INFO:\")\n",
        "    print(main_df.info())\n",
        "    \n",
        "    # Check for behavioral features and target columns\n",
        "    behavioral_cols = [col for col in main_df.columns if any(word in col.lower() for word in \n",
        "                      ['time', 'social', 'going', 'friends', 'post', 'alone', 'event', 'outside'])]\n",
        "    psychological_cols = [col for col in main_df.columns if any(word in col.lower() for word in \n",
        "                         ['stage', 'fear', 'drained', 'socializing'])]\n",
        "    target_cols = [col for col in main_df.columns if any(word in col.lower() for word in \n",
        "                  ['personality', 'class', 'target', 'extrovert', 'introvert'])]\n",
        "    \n",
        "    print(f\"\\nIDENTIFIED COLUMNS:\")\n",
        "    print(f\"   Behavioral features: {behavioral_cols}\")\n",
        "    print(f\"   Psychological indicators: {psychological_cols}\")\n",
        "    print(f\"   Target variables: {target_cols}\")\n",
        "else:\n",
        "    print(\"FAILED TO LOAD MAIN PERSONALITY DATASET\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Data Quality Assessment\n",
        "\n",
        "Analyzing the quality and characteristics of our personality dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MAIN DATASET QUALITY ANALYSIS\n",
            "============================================================\n",
            "Shape: (2900, 8)\n",
            "\n",
            "MISSING VALUES ANALYSIS:\n",
            "                      Column  Missing_Count  Missing_Percentage\n",
            "5        Friends_circle_size             77            2.655172\n",
            "1                 Stage_fear             73            2.517241\n",
            "3              Going_outside             66            2.275862\n",
            "6             Post_frequency             65            2.241379\n",
            "0           Time_spent_Alone             63            2.172414\n",
            "2    Social_event_attendance             62            2.137931\n",
            "4  Drained_after_socializing             52            1.793103\n",
            "7                Personality              0            0.000000\n",
            "\n",
            "Total missing values: 458\n",
            "Columns with missing data: 7\n",
            "\n",
            "DUPLICATE ANALYSIS:\n",
            "Number of duplicate rows: 388\n",
            "Percentage of duplicates: 13.38%\n",
            "\n",
            "DATA TYPES ANALYSIS:\n",
            "   Numerical columns (5): ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']\n",
            "   Categorical columns (3): ['Stage_fear', 'Drained_after_socializing', 'Personality']\n",
            "\n",
            "NUMERICAL FEATURES SUMMARY:\n",
            "       Time_spent_Alone  Social_event_attendance  Going_outside  \\\n",
            "count       2837.000000              2838.000000    2834.000000   \n",
            "mean           4.505816                 3.963354       3.000000   \n",
            "std            3.479192                 2.903827       2.247327   \n",
            "min            0.000000                 0.000000       0.000000   \n",
            "25%            2.000000                 2.000000       1.000000   \n",
            "50%            4.000000                 3.000000       3.000000   \n",
            "75%            8.000000                 6.000000       5.000000   \n",
            "max           11.000000                10.000000       7.000000   \n",
            "\n",
            "       Friends_circle_size  Post_frequency  \n",
            "count          2823.000000     2835.000000  \n",
            "mean              6.268863        3.564727  \n",
            "std               4.289693        2.926582  \n",
            "min               0.000000        0.000000  \n",
            "25%               3.000000        1.000000  \n",
            "50%               5.000000        3.000000  \n",
            "75%              10.000000        6.000000  \n",
            "max              15.000000       10.000000  \n",
            "\n",
            "CATEGORICAL FEATURES SUMMARY:\n",
            "\n",
            "Stage_fear:\n",
            "Stage_fear\n",
            "No     1417\n",
            "Yes    1410\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Drained_after_socializing:\n",
            "Drained_after_socializing\n",
            "No     1441\n",
            "Yes    1407\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Personality:\n",
            "Personality\n",
            "Extrovert    1491\n",
            "Introvert    1409\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TARGET VARIABLE ANALYSIS:\n",
            "Class distribution:\n",
            "   Extrovert: 1491 (51.4%)\n",
            "   Introvert: 1409 (48.6%)\n",
            "\n",
            "Class balance ratio: 1.06:1\n",
            "Balance assessment: WELL BALANCED\n"
          ]
        }
      ],
      "source": [
        "# Analyze main dataset quality\n",
        "if main_df is not None:\n",
        "    print(\"=\"*60)\n",
        "    print(\"MAIN DATASET QUALITY ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Shape: {main_df.shape}\")\n",
        "    \n",
        "    # Missing values analysis\n",
        "    print(f\"\\nMISSING VALUES ANALYSIS:\")\n",
        "    missing_counts = main_df.isnull().sum()\n",
        "    missing_percentages = (missing_counts / len(main_df)) * 100\n",
        "    \n",
        "    missing_summary = pd.DataFrame({\n",
        "        'Column': missing_counts.index,\n",
        "        'Missing_Count': missing_counts.values,\n",
        "        'Missing_Percentage': missing_percentages.values\n",
        "    }).sort_values('Missing_Count', ascending=False)\n",
        "    \n",
        "    print(missing_summary)\n",
        "    \n",
        "    total_missing = missing_counts.sum()\n",
        "    print(f\"\\nTotal missing values: {total_missing}\")\n",
        "    print(f\"Columns with missing data: {(missing_counts > 0).sum()}\")\n",
        "    \n",
        "    # Duplicate analysis\n",
        "    print(f\"\\nDUPLICATE ANALYSIS:\")\n",
        "    duplicates = main_df.duplicated().sum()\n",
        "    print(f\"Number of duplicate rows: {duplicates}\")\n",
        "    print(f\"Percentage of duplicates: {(duplicates/len(main_df))*100:.2f}%\")\n",
        "    \n",
        "    # Data types analysis\n",
        "    print(f\"\\nDATA TYPES ANALYSIS:\")\n",
        "    numerical_cols = main_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_cols = main_df.select_dtypes(include=['object']).columns.tolist()\n",
        "    \n",
        "    print(f\"   Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
        "    print(f\"   Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
        "    \n",
        "    # Basic statistics for numerical columns\n",
        "    if numerical_cols:\n",
        "        print(f\"\\nNUMERICAL FEATURES SUMMARY:\")\n",
        "        print(main_df[numerical_cols].describe())\n",
        "    \n",
        "    # Value counts for categorical columns\n",
        "    if categorical_cols:\n",
        "        print(f\"\\nCATEGORICAL FEATURES SUMMARY:\")\n",
        "        for col in categorical_cols:\n",
        "            print(f\"\\n{col}:\")\n",
        "            print(main_df[col].value_counts())\n",
        "            \n",
        "    # Target variable analysis (assuming 'Personality' is the target)\n",
        "    if 'Personality' in main_df.columns:\n",
        "        print(f\"\\nTARGET VARIABLE ANALYSIS:\")\n",
        "        target_counts = main_df['Personality'].value_counts()\n",
        "        target_percentages = main_df['Personality'].value_counts(normalize=True) * 100\n",
        "        \n",
        "        print(f\"Class distribution:\")\n",
        "        for personality, count in target_counts.items():\n",
        "            pct = target_percentages[personality]\n",
        "            print(f\"   {personality}: {count} ({pct:.1f}%)\")\n",
        "        \n",
        "        # Class balance ratio\n",
        "        balance_ratio = target_counts.max() / target_counts.min()\n",
        "        print(f\"\\nClass balance ratio: {balance_ratio:.2f}:1\")\n",
        "        \n",
        "        if balance_ratio <= 1.5:\n",
        "            balance_status = \"WELL BALANCED\"\n",
        "        elif balance_ratio <= 3.0:\n",
        "            balance_status = \"MODERATELY IMBALANCED\"\n",
        "        else:\n",
        "            balance_status = \"HIGHLY IMBALANCED\"\n",
        "        \n",
        "        print(f\"Balance assessment: {balance_status}\")\n",
        "else:\n",
        "    print(\"No dataset available for quality analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: Feature Analysis and Validation\n",
        "\n",
        "Detailed analysis of behavioral and psychological features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FEATURE VALIDATION AND ANALYSIS\n",
            "============================================================\n",
            "FEATURE CATEGORIZATION:\n",
            "\n",
            "BEHAVIORAL FEATURES:\n",
            "   Available (5): ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']\n",
            "\n",
            "PSYCHOLOGICAL INDICATORS:\n",
            "   Available (2): ['Stage_fear', 'Drained_after_socializing']\n",
            "\n",
            "TARGET VARIABLE:\n",
            "   Available (1): ['Personality']\n",
            "\n",
            "FEATURE RANGE VALIDATION:\n",
            "   Time_spent_Alone: Range [0.0, 11.0] (Expected: [0, 10])\n",
            "      WARNING: Values outside expected range [0, 10]\n",
            "   Social_event_attendance: Range [0.0, 10.0] (Expected: [0, 10])\n",
            "   Going_outside: Range [0.0, 7.0] (Expected: [0, 10])\n",
            "   Post_frequency: Range [0.0, 10.0] (Expected: [0, 10])\n",
            "   Friends_circle_size: Range [0.0, 15.0] (Expected: >= 0)\n",
            "\n",
            "CATEGORICAL FEATURES VALIDATION:\n",
            "   Stage_fear:\n",
            "      Expected: ['Yes', 'No']\n",
            "      Actual: ['No', 'Yes', nan]\n",
            "      WARNING: Unexpected values found: [nan]\n",
            "   Drained_after_socializing:\n",
            "      Expected: ['Yes', 'No']\n",
            "      Actual: ['No', 'Yes', nan]\n",
            "      WARNING: Unexpected values found: [nan]\n",
            "   Personality:\n",
            "      Expected: ['Extrovert', 'Introvert']\n",
            "      Actual: ['Extrovert', 'Introvert']\n",
            "\n",
            "DATA CONSISTENCY CHECKS:\n",
            "   Sample sizes: Extroverts (1491), Introverts (1409)\n",
            "   Behavioral patterns comparison:\n",
            "      Time_spent_Alone: Extrovert (2.07) vs Introvert (7.08)\n",
            "      Social_event_attendance: Extrovert (6.02) vs Introvert (1.78)\n",
            "      Going_outside: Extrovert (4.63) vs Introvert (1.27)\n",
            "      Friends_circle_size: Extrovert (9.17) vs Introvert (3.20)\n",
            "      Post_frequency: Extrovert (5.64) vs Introvert (1.37)\n"
          ]
        }
      ],
      "source": [
        "# Feature validation and analysis\n",
        "if main_df is not None:\n",
        "    print(\"=\"*60)\n",
        "    print(\"FEATURE VALIDATION AND ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Define feature categories based on personality psychology\n",
        "    feature_categories = {\n",
        "        'behavioral_features': [\n",
        "            'Time_spent_Alone', 'Social_event_attendance', 'Going_outside', \n",
        "            'Friends_circle_size', 'Post_frequency'\n",
        "        ],\n",
        "        'psychological_indicators': [\n",
        "            'Stage_fear', 'Drained_after_socializing'\n",
        "        ],\n",
        "        'target_variable': [\n",
        "            'Personality'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    print(\"FEATURE CATEGORIZATION:\")\n",
        "    for category, features in feature_categories.items():\n",
        "        available_features = [f for f in features if f in main_df.columns]\n",
        "        missing_features = [f for f in features if f not in main_df.columns]\n",
        "        \n",
        "        print(f\"\\n{category.upper().replace('_', ' ')}:\")\n",
        "        print(f\"   Available ({len(available_features)}): {available_features}\")\n",
        "        if missing_features:\n",
        "            print(f\"   Missing ({len(missing_features)}): {missing_features}\")\n",
        "    \n",
        "    # Validate feature ranges and distributions\n",
        "    print(f\"\\nFEATURE RANGE VALIDATION:\")\n",
        "    \n",
        "    # Expected ranges for behavioral features (0-10 scale)\n",
        "    scale_features = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Post_frequency']\n",
        "    for feature in scale_features:\n",
        "        if feature in main_df.columns:\n",
        "            min_val = main_df[feature].min()\n",
        "            max_val = main_df[feature].max()\n",
        "            print(f\"   {feature}: Range [{min_val}, {max_val}] (Expected: [0, 10])\")\n",
        "            \n",
        "            # Check for outliers\n",
        "            if min_val < 0 or max_val > 10:\n",
        "                print(f\"      WARNING: Values outside expected range [0, 10]\")\n",
        "    \n",
        "    # Friends circle size validation\n",
        "    if 'Friends_circle_size' in main_df.columns:\n",
        "        min_friends = main_df['Friends_circle_size'].min()\n",
        "        max_friends = main_df['Friends_circle_size'].max()\n",
        "        print(f\"   Friends_circle_size: Range [{min_friends}, {max_friends}] (Expected: >= 0)\")\n",
        "        \n",
        "        if min_friends < 0:\n",
        "            print(f\"      WARNING: Negative values found\")\n",
        "    \n",
        "    # Categorical features validation\n",
        "    print(f\"\\nCATEGORICAL FEATURES VALIDATION:\")\n",
        "    \n",
        "    categorical_features = {\n",
        "        'Stage_fear': ['Yes', 'No'],\n",
        "        'Drained_after_socializing': ['Yes', 'No'],\n",
        "        'Personality': ['Extrovert', 'Introvert']\n",
        "    }\n",
        "    \n",
        "    for feature, expected_values in categorical_features.items():\n",
        "        if feature in main_df.columns:\n",
        "            actual_values = main_df[feature].unique()\n",
        "            print(f\"   {feature}:\")\n",
        "            print(f\"      Expected: {expected_values}\")\n",
        "            print(f\"      Actual: {list(actual_values)}\")\n",
        "            \n",
        "            # Check for unexpected values\n",
        "            unexpected = set(actual_values) - set(expected_values)\n",
        "            if unexpected:\n",
        "                print(f\"      WARNING: Unexpected values found: {list(unexpected)}\")\n",
        "    \n",
        "    # Check for data consistency\n",
        "    print(f\"\\nDATA CONSISTENCY CHECKS:\")\n",
        "    \n",
        "    # Check if extroverts have expected behavioral patterns\n",
        "    if 'Personality' in main_df.columns:\n",
        "        extroverts = main_df[main_df['Personality'] == 'Extrovert']\n",
        "        introverts = main_df[main_df['Personality'] == 'Introvert']\n",
        "        \n",
        "        print(f\"   Sample sizes: Extroverts ({len(extroverts)}), Introverts ({len(introverts)})\")\n",
        "        \n",
        "        # Compare mean values for behavioral features\n",
        "        behavioral_features = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', \n",
        "                             'Friends_circle_size', 'Post_frequency']\n",
        "        \n",
        "        print(f\"   Behavioral patterns comparison:\")\n",
        "        for feature in behavioral_features:\n",
        "            if feature in main_df.columns:\n",
        "                ext_mean = extroverts[feature].mean()\n",
        "                int_mean = introverts[feature].mean()\n",
        "                print(f\"      {feature}: Extrovert ({ext_mean:.2f}) vs Introvert ({int_mean:.2f})\")\n",
        "                \n",
        "                # Logical consistency check\n",
        "                if feature in ['Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']:\n",
        "                    if ext_mean <= int_mean:\n",
        "                        print(f\"         NOTE: Expected extroverts to have higher values\")\n",
        "                elif feature == 'Time_spent_Alone':\n",
        "                    if ext_mean >= int_mean:\n",
        "                        print(f\"         NOTE: Expected introverts to spend more time alone\")\n",
        "else:\n",
        "    print(\"No dataset available for feature analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 5: Data Export and Preparation\n",
        "\n",
        "Save the processed datasets for the next stages of the pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATA EXPORT AND PREPARATION\n",
            "============================================================\n",
            "Using main project data directory: ../data/processed\n",
            "Saved raw personality data to ../data/processed\\raw_personality_data.csv\n",
            "Saved feature metadata to ../data/processed\\feature_metadata.csv\n",
            "\n",
            "============================================================\n",
            "DATA RETRIEVAL SUMMARY\n",
            "============================================================\n",
            "Main personality dataset: SUCCESS\n",
            "Total samples in dataset: 2900\n",
            "Features available: 8\n",
            "Behavioral features: 5\n",
            "Psychological indicators: 2\n",
            "Target variable: Available\n",
            "\n",
            "Data Quality Summary:\n",
            "   Missing values: 458\n",
            "   Duplicate records: 388\n",
            "   Class balance ratio: 1.06:1\n",
            "\n",
            "Dataset ready for the next phase: DATA PREPARATION!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Save datasets to existing main data directory ONLY\n",
        "print(\"=\"*60)\n",
        "print(\"DATA EXPORT AND PREPARATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Always use the main project data directory (never create local ones)\n",
        "# When running from notebooks/, the main data folder is at ../data/processed\n",
        "processed_dir = \"../data/processed\"\n",
        "\n",
        "# Verify the main data directory exists\n",
        "if os.path.exists(processed_dir):\n",
        "    print(f\"Using main project data directory: {processed_dir}\")\n",
        "else:\n",
        "    print(f\"ERROR: Main data directory not found at {processed_dir}\")\n",
        "    print(\"Please ensure you're running from the notebooks/ folder and data/processed exists at project root\")\n",
        "    processed_dir = None\n",
        "\n",
        "if processed_dir is not None and main_df is not None:\n",
        "    # Save raw personality dataset\n",
        "    filepath = os.path.join(processed_dir, \"raw_personality_data.csv\")\n",
        "    main_df.to_csv(filepath, index=False, encoding='utf-8')\n",
        "    print(f\"Saved raw personality data to {filepath}\")\n",
        "    \n",
        "    # Create feature metadata for reference\n",
        "    feature_metadata = {\n",
        "        'feature_name': [],\n",
        "        'feature_type': [],\n",
        "        'category': [],\n",
        "        'description': [],\n",
        "        'expected_range': []\n",
        "    }\n",
        "    \n",
        "    # Behavioral features metadata\n",
        "    behavioral_features_info = {\n",
        "        'Time_spent_Alone': ('numerical', 'behavioral', 'Hours spent alone per day', '0-10'),\n",
        "        'Social_event_attendance': ('numerical', 'behavioral', 'Frequency of social event attendance', '0-10'),\n",
        "        'Going_outside': ('numerical', 'behavioral', 'Frequency of going outside', '0-10'),\n",
        "        'Friends_circle_size': ('numerical', 'behavioral', 'Number of close friends', '>=0'),\n",
        "        'Post_frequency': ('numerical', 'behavioral', 'Social media posting frequency', '0-10')\n",
        "    }\n",
        "    \n",
        "    # Psychological features metadata\n",
        "    psychological_features_info = {\n",
        "        'Stage_fear': ('categorical', 'psychological', 'Has stage fear/performance anxiety', 'Yes/No'),\n",
        "        'Drained_after_socializing': ('categorical', 'psychological', 'Gets drained after socializing', 'Yes/No')\n",
        "    }\n",
        "    \n",
        "    # Target variable metadata\n",
        "    target_features_info = {\n",
        "        'Personality': ('categorical', 'target', 'Personality type classification', 'Extrovert/Introvert')\n",
        "    }\n",
        "    \n",
        "    # Combine all feature information\n",
        "    all_features_info = {**behavioral_features_info, **psychological_features_info, **target_features_info}\n",
        "    \n",
        "    for feature, (ftype, category, description, expected_range) in all_features_info.items():\n",
        "        if feature in main_df.columns:\n",
        "            feature_metadata['feature_name'].append(feature)\n",
        "            feature_metadata['feature_type'].append(ftype)\n",
        "            feature_metadata['category'].append(category)\n",
        "            feature_metadata['description'].append(description)\n",
        "            feature_metadata['expected_range'].append(expected_range)\n",
        "    \n",
        "    # Save feature metadata\n",
        "    metadata_df = pd.DataFrame(feature_metadata)\n",
        "    metadata_filepath = os.path.join(processed_dir, \"feature_metadata.csv\")\n",
        "    metadata_df.to_csv(metadata_filepath, index=False, encoding='utf-8')\n",
        "    print(f\"Saved feature metadata to {metadata_filepath}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"DATA RETRIEVAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Main personality dataset: {'SUCCESS' if main_df is not None else 'FAILED'}\")\n",
        "\n",
        "if main_df is not None:\n",
        "    print(f\"Total samples in dataset: {len(main_df)}\")\n",
        "    print(f\"Features available: {len(main_df.columns)}\")\n",
        "    print(f\"Behavioral features: {len([col for col in main_df.columns if col in ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']])}\")\n",
        "    print(f\"Psychological indicators: {len([col for col in main_df.columns if col in ['Stage_fear', 'Drained_after_socializing']])}\")\n",
        "    print(f\"Target variable: {'Available' if 'Personality' in main_df.columns else 'Missing'}\")\n",
        "    \n",
        "    # Data quality summary\n",
        "    missing_values = main_df.isnull().sum().sum()\n",
        "    duplicates = main_df.duplicated().sum()\n",
        "    print(f\"\\nData Quality Summary:\")\n",
        "    print(f\"   Missing values: {missing_values}\")\n",
        "    print(f\"   Duplicate records: {duplicates}\")\n",
        "    \n",
        "    if 'Personality' in main_df.columns:\n",
        "        target_counts = main_df['Personality'].value_counts()\n",
        "        balance_ratio = target_counts.max() / target_counts.min()\n",
        "        print(f\"   Class balance ratio: {balance_ratio:.2f}:1\")\n",
        "    \n",
        "print(f\"\\nDataset ready for the next phase: DATA PREPARATION!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook successfully completed the data retrieval phase for the Extrovert-Introvert Classification project:\n",
        "\n",
        "1. **Data Loading**: Loaded personality dataset with robust encoding handling\n",
        "2. **Quality Assessment**: Analyzed dataset structure, missing values, and distributions\n",
        "3. **Feature Validation**: Validated behavioral and psychological features against expected ranges\n",
        "4. **Consistency Checks**: Verified logical consistency between personality types and behavioral patterns\n",
        "5. **Export**: Saved processed datasets and metadata for the next pipeline stages\n",
        "\n",
        "### Next Steps:\n",
        "- Proceed to `02_data_preparation.ipynb` for data cleaning and preprocessing\n",
        "- The processed datasets are available in `data/processed/` directory\n",
        "- Feature metadata is ready for use in feature engineering and analysis\n",
        "\n",
        "### Key Outputs:\n",
        "- `raw_personality_data.csv`: Primary personality classification dataset\n",
        "- `feature_metadata.csv`: Comprehensive feature documentation with types, categories, and descriptions\n",
        "\n",
        "### Dataset Characteristics:\n",
        "- **Domain**: Personality Psychology / Behavioral Analysis\n",
        "- **Task**: Binary Classification (Extrovert vs Introvert)\n",
        "- **Features**: Behavioral patterns, psychological indicators, and social preferences\n",
        "- **Target**: Personality type classification\n",
        "\n",
        "### Data Quality Status:\n",
        "- Missing values: Requires handling in data preparation phase\n",
        "- Data consistency: Behavioral patterns align with psychological expectations\n",
        "- Feature validity: All features within expected ranges and formats\n",
        "- Class balance: Suitable for machine learning modeling\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
